## 2. Ethics Definitions

[Back to TOC](/?id=table-of-contents)

Let's define some terms to set the stage for this discussion


### 2.1 Ethics

The term "ethics" comes from the [Greek word "ethikos"](https://en.wikipedia.org/wiki/Ethics) and it's root "ethos" meaning _character or moral nature_. It refers to the **set of shared values and moral principles** that govern our behaviors in society. Our code of ethics is usually based on widely-accepted ideas of _right and wrong_ which lead to informal rules (or _norms_) that we follow voluntarily, for the collective good.

### 2.2 Data Ethics

Data ethics is [a branch of ethics](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) that **studies & evaluates moral problems related to data, algorithms and corresponding practices** to formulate and support morally good solutions (right conduct or values) where:

* `data` = generation, recording, curation, dissemination, sharing & usage 
* `algorithms` = AI, agents, machine learning, bots 
* `practices` = responsible innovation, ethical hacking, codes of conduct

We'll look at data ethics from two perspectives:  **conceptual** (understanding the broad ethical challenges or potential harms of big data and AI) and **applied** (implementing ethical principles and practices in professional and industry contexts). We'll look at _case studies_ that put ethics concepts in real-world contexts, and _ethics cultures_ driven by social and legal frameworks that make adoption of these principles and practices easier.

### 2.3 Applied Ethics

Applied ethics is the **practical application of ethical principles** to a given project, product, or process.

Applied _data ethics_ focuses on first asking moral questions (_"is this fair? is this right? what harm can this do?"_) about our data collection and usage in the context of real-world algorithms and AI scenarios. Then taking corrective actions (_"did I test model accuracy across diverse groups? did I secure the data?"_) to prevent unintended consequences that may cause potential harms to individuals or society at large.

### 2.4 Ethics vs. Laws

Ethics are not laws. They are shared values and moral principles that we follow voluntarily. 

But they can _influence_ the creation of legal and social frameworks that drive applied ethics in real-world contexts. Some examples of ways in which ethics can support governance:

 * **Professional codes of conduct** to govern ethical behavior of _individuals and groups_. Ex: the [Hippocratic Oath](https://en.wikipedia.org/wiki/Hippocratic_Oath) of medical ethics identified principles like data confidentiality (led to _doctor-patient privilege_ laws) and non-maleficence (popularly known as _first, do no harm_) that are still widely adopted.
 * **Regulatory standards** to govern ethical behavior in _organizations and industries_. Ex: the [EU General Data Protection Regulation](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation) (GDPR) enhances individuals' control and rights over their personal data, protecting privacy and more. It has since inspired other laws like the [California Consumer Privacy Act](https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act).
 * **Corporate frameworks** to ensure ethical practices _in product design and development_. Ex: Microsoft's [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai) initiative defines [6 guiding principles](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) with [support tools and resources](https://www.microsoft.com/en-us/ai/responsible-ai-resources) to ease adoption. Similiar _ethical AI_ initiatives have been defined by [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/), [Accenture](https://www.accenture.com/_acnmedia/PDF-149/Accenture-Responsible-AI-Final.pdf#zoom=50) and others.
